{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X_train = np.asarray(X_train, dtype=np.float32)\n",
    "y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
    "X_test = np.asarray(X_test, dtype=np.float32)\n",
    "y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
    "\n",
    "num_training=49000\n",
    "num_validation=1000\n",
    "num_test=10000\n",
    "\n",
    "\n",
    "mask = range(num_training, num_training + num_validation)\n",
    "X_val = X_train[mask]\n",
    "y_val = y_train[mask]\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "mask = range(num_test)\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "#print(X_train[0].shape)\n",
    "\n",
    "mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "X_train = (X_train - mean_pixel) / std_pixel\n",
    "X_val = (X_val - mean_pixel) / std_pixel\n",
    "X_test = (X_test - mean_pixel) / std_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(10000).batch(64)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, 3, activation = None)\n",
    "        self.relu1 = tf.keras.layers.ReLU()\n",
    "        self.drop1 = tf.keras.layers.Dropout(rate = 0.5)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 3, activation = None)\n",
    "        self.relu2 = tf.keras.layers.ReLU()\n",
    "        self.drop2 = tf.keras.layers.Dropout(rate = 0.5)\n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, 3, activation = None)\n",
    "        self.relu3 = tf.keras.layers.ReLU()\n",
    "        self.drop3 = tf.keras.layers.Dropout(rate = 0.5)\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(64, activation = 'relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(64, activation = 'relu')\n",
    "        self.fc3 = tf.keras.layers.Dense(10)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        #x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.conv2(x)\n",
    "        #x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.drop3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.fc3(x)\n",
    "        \n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = MyModel()\n",
    "    \n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer = tf.keras.optimizers.Adam(),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for decaying the learning rate.\n",
    "# You can define any decay function you need.\n",
    "def decay(epoch):\n",
    "    if epoch < 3:\n",
    "        return 1e-3\n",
    "    elif epoch >= 3 and epoch < 7:\n",
    "        return 1e-4\n",
    "    else:\n",
    "        return 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
    "                                                      model.optimizer.lr.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                       save_weights_only=True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
    "    PrintLR()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "  2/766 [..............................] - ETA: 11:36 - loss: 0.9782 - accuracy: 0.6641WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.604102). Check your callbacks.\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.9782 - accuracy: 0.6545\n",
      "Learning rate for epoch 1 is 0.0010000000474974513\n",
      "766/766 [==============================] - 519s 678ms/step - loss: 0.9782 - accuracy: 0.6545 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.8953 - accuracy: 0.6846\n",
      "Learning rate for epoch 2 is 0.0010000000474974513\n",
      "766/766 [==============================] - 455s 595ms/step - loss: 0.8953 - accuracy: 0.6846 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.8266 - accuracy: 0.7093\n",
      "Learning rate for epoch 3 is 0.0010000000474974513\n",
      "766/766 [==============================] - 446s 583ms/step - loss: 0.8266 - accuracy: 0.7093 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.6708 - accuracy: 0.7646\n",
      "Learning rate for epoch 4 is 9.999999747378752e-05\n",
      "766/766 [==============================] - 447s 583ms/step - loss: 0.6708 - accuracy: 0.7646 - lr: 1.0000e-04\n",
      "Epoch 5/15\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.6389 - accuracy: 0.7760\n",
      "Learning rate for epoch 5 is 9.999999747378752e-05\n",
      "766/766 [==============================] - 446s 582ms/step - loss: 0.6389 - accuracy: 0.7760 - lr: 1.0000e-04\n",
      "Epoch 6/15\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.6239 - accuracy: 0.7801\n",
      "Learning rate for epoch 6 is 9.999999747378752e-05\n",
      "766/766 [==============================] - 456s 595ms/step - loss: 0.6239 - accuracy: 0.7801 - lr: 1.0000e-04\n",
      "Epoch 7/15\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.6086 - accuracy: 0.7843\n",
      "Learning rate for epoch 7 is 9.999999747378752e-05\n",
      "766/766 [==============================] - 462s 603ms/step - loss: 0.6086 - accuracy: 0.7843 - lr: 1.0000e-04\n",
      "Epoch 8/15\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.5849 - accuracy: 0.7938\n",
      "Learning rate for epoch 8 is 9.999999747378752e-06\n",
      "766/766 [==============================] - 454s 592ms/step - loss: 0.5849 - accuracy: 0.7938 - lr: 1.0000e-05\n",
      "Epoch 9/15\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.5820 - accuracy: 0.7945\n",
      "Learning rate for epoch 9 is 9.999999747378752e-06\n",
      "766/766 [==============================] - 447s 584ms/step - loss: 0.5820 - accuracy: 0.7945 - lr: 1.0000e-05\n",
      "Epoch 10/15\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.5803 - accuracy: 0.7967\n",
      "Learning rate for epoch 10 is 9.999999747378752e-06\n",
      "766/766 [==============================] - 443s 578ms/step - loss: 0.5803 - accuracy: 0.7967 - lr: 1.0000e-05\n",
      "Epoch 11/15\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.5818 - accuracy: 0.7955\n",
      "Learning rate for epoch 11 is 9.999999747378752e-06\n",
      "766/766 [==============================] - 500s 653ms/step - loss: 0.5818 - accuracy: 0.7955 - lr: 1.0000e-05\n",
      "Epoch 12/15\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.5760 - accuracy: 0.7978\n",
      "Learning rate for epoch 12 is 9.999999747378752e-06\n",
      "766/766 [==============================] - 483s 630ms/step - loss: 0.5760 - accuracy: 0.7978 - lr: 1.0000e-05\n",
      "Epoch 13/15\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.7959\n",
      "Learning rate for epoch 13 is 9.999999747378752e-06\n",
      "766/766 [==============================] - 515s 672ms/step - loss: 0.5765 - accuracy: 0.7959 - lr: 1.0000e-05\n",
      "Epoch 14/15\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.5692 - accuracy: 0.8009\n",
      "Learning rate for epoch 14 is 9.999999747378752e-06\n",
      "766/766 [==============================] - 482s 629ms/step - loss: 0.5692 - accuracy: 0.8009 - lr: 1.0000e-05\n",
      "Epoch 15/15\n",
      "766/766 [==============================] - ETA: 0s - loss: 0.5725 - accuracy: 0.7993\n",
      "Learning rate for epoch 15 is 9.999999747378752e-06\n",
      "766/766 [==============================] - 484s 632ms/step - loss: 0.5725 - accuracy: 0.7993 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xfe07c07a48>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=15, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D has no label.\n",
      " Volume Serial Number is 5E15-AB74\n",
      "\n",
      " Directory of D:\\Behnam\\Uni\\Videos and lectures\\Machine Learning\\github\\Deep Learning\\Tensorflow\\Cifar10-TF\\training_checkpoints\n",
      "\n",
      "04/03/2020  07:24 PM    <DIR>          .\n",
      "04/03/2020  07:24 PM    <DIR>          ..\n",
      "04/03/2020  07:24 PM                69 checkpoint\n",
      "04/03/2020  07:16 PM        67,634,721 ckpt_1.data-00000-of-00001\n",
      "04/03/2020  07:16 PM             2,860 ckpt_1.index\n",
      "04/03/2020  07:24 PM        67,634,721 ckpt_2.data-00000-of-00001\n",
      "04/03/2020  07:24 PM             2,860 ckpt_2.index\n",
      "               5 File(s)    135,275,231 bytes\n",
      "               2 Dir(s)  389,232,144,384 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir {'training_checkpoints'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           multiple                  896       \n",
      "_________________________________________________________________\n",
      "re_lu_27 (ReLU)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           multiple                  18496     \n",
      "_________________________________________________________________\n",
      "re_lu_28 (ReLU)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           multiple                  73856     \n",
      "_________________________________________________________________\n",
      "re_lu_29 (ReLU)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             multiple                  5537856   \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             multiple                  650       \n",
      "=================================================================\n",
      "Total params: 5,635,914\n",
      "Trainable params: 5,635,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 95ms/step - loss: 0.8564 - accuracy: 0.7240\n",
      "Eval loss: 0.8563759922981262, Eval Accuracy: 0.7239999771118164\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "eval_loss, eval_acc = model.evaluate(val_ds)\n",
    "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\mafakheri\\appdata\\local\\continuum\\anaconda3\\envs\\tf_20_env\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\users\\mafakheri\\appdata\\local\\continuum\\anaconda3\\envs\\tf_20_env\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\mafakheri\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_20_env\\Scripts\\tensorboard.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"c:\\users\\mafakheri\\appdata\\local\\continuum\\anaconda3\\envs\\tf_20_env\\lib\\site-packages\\tensorboard\\main.py\", line 75, in run_main\n",
      "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
      "  File \"c:\\users\\mafakheri\\appdata\\local\\continuum\\anaconda3\\envs\\tf_20_env\\lib\\site-packages\\absl\\app.py\", line 299, in run\n",
      "    _run_main(main, args)\n",
      "  File \"c:\\users\\mafakheri\\appdata\\local\\continuum\\anaconda3\\envs\\tf_20_env\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"c:\\users\\mafakheri\\appdata\\local\\continuum\\anaconda3\\envs\\tf_20_env\\lib\\site-packages\\tensorboard\\program.py\", line 289, in main\n",
      "    return runner(self.flags) or 0\n",
      "  File \"c:\\users\\mafakheri\\appdata\\local\\continuum\\anaconda3\\envs\\tf_20_env\\lib\\site-packages\\tensorboard\\program.py\", line 305, in _run_serve_subcommand\n",
      "    server = self._make_server()\n",
      "  File \"c:\\users\\mafakheri\\appdata\\local\\continuum\\anaconda3\\envs\\tf_20_env\\lib\\site-packages\\tensorboard\\program.py\", line 409, in _make_server\n",
      "    self.flags, self.plugin_loaders, self.assets_zip_provider\n",
      "  File \"c:\\users\\mafakheri\\appdata\\local\\continuum\\anaconda3\\envs\\tf_20_env\\lib\\site-packages\\tensorboard\\backend\\application.py\", line 184, in standard_tensorboard_wsgi\n",
      "    flags, plugin_loaders, data_provider, assets_zip_provider, multiplexer\n",
      "  File \"c:\\users\\mafakheri\\appdata\\local\\continuum\\anaconda3\\envs\\tf_20_env\\lib\\site-packages\\tensorboard\\backend\\application.py\", line 265, in TensorBoardWSGIApp\n",
      "    tbplugins, flags.path_prefix, data_provider, experimental_plugins\n",
      "  File \"c:\\users\\mafakheri\\appdata\\local\\continuum\\anaconda3\\envs\\tf_20_env\\lib\\site-packages\\tensorboard\\backend\\application.py\", line 338, in __init__\n",
      "    \"Duplicate plugins for name %s\" % plugin.plugin_name\n",
      "ValueError: Duplicate plugins for name projector\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir='./logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'saved_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(path, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 101ms/step - loss: 1.0475 - accuracy: 0.6430\n",
      "Eval loss: 1.047545075416565, Eval Accuracy: 0.6430000066757202\n"
     ]
    }
   ],
   "source": [
    "unreplicated_model = tf.keras.models.load_model(path)\n",
    "\n",
    "unreplicated_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "eval_loss, eval_acc = unreplicated_model.evaluate(val_ds)\n",
    "\n",
    "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 92ms/step - loss: 1.0475 - accuracy: 0.6430\n",
      "Eval loss: 1.047545075416565, Eval Accuracy: 0.6430000066757202\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    replicated_model = tf.keras.models.load_model(path)\n",
    "    replicated_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                           optimizer=tf.keras.optimizers.Adam(),\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    eval_loss, eval_acc = replicated_model.evaluate(val_ds)\n",
    "    print ('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
