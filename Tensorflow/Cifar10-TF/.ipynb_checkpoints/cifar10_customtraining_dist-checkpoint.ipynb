{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X_train = np.asarray(X_train, dtype=np.float32)\n",
    "y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
    "X_test = np.asarray(X_test, dtype=np.float32)\n",
    "y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
    "\n",
    "num_training=49000\n",
    "num_validation=1000\n",
    "num_test=10000\n",
    "\n",
    "BUFFER_SIZE = len(X_train)\n",
    "\n",
    "mask = range(num_training, num_training + num_validation)\n",
    "X_val = X_train[mask]\n",
    "y_val = y_train[mask]\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "mask = range(num_test)\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "#print(X_train[0].shape)\n",
    "\n",
    "mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "X_train = (X_train - mean_pixel) / std_pixel\n",
    "X_val = (X_val - mean_pixel) / std_pixel\n",
    "X_test = (X_test - mean_pixel) / std_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(BUFFER_SIZE).batch(64)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, 3, activation = None)\n",
    "        self.relu1 = tf.keras.layers.ReLU()\n",
    "        self.drop1 = tf.keras.layers.Dropout(rate = 0.5)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 3, activation = None)\n",
    "        self.relu2 = tf.keras.layers.ReLU()\n",
    "        self.drop2 = tf.keras.layers.Dropout(rate = 0.5)\n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, 3, activation = None)\n",
    "        self.relu3 = tf.keras.layers.ReLU()\n",
    "        self.drop3 = tf.keras.layers.Dropout(rate = 0.5)\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(64, activation = 'relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(64, activation = 'relu')\n",
    "        self.fc3 = tf.keras.layers.Dense(10)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        #x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.conv2(x)\n",
    "        #x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.drop3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dist_ds = strategy.experimental_distribute_dataset(train_ds)\n",
    "val_dist_ds = strategy.experimental_distribute_dataset(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.distribute.input_lib.DistributedDataset"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dist_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 32, 32, 3])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgbatch, labels = next(iter(train_dist_ds))\n",
    "(imgbatch[:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                               reduction=tf.keras.losses.Reduction.NONE)\n",
    "    learning_rate = 1e-3\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "    val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "    val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "    model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    def train_step(inputs):\n",
    "        images, labels = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(images, training = True)\n",
    "            loss_per_example = loss_object(labels, predictions)\n",
    "            #tf.print(tf.math.reduce_sum(loss_per_example))\n",
    "            loss = tf.nn.compute_average_loss(loss_per_example, global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "            #tf.print(loss)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        #print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(), loss.numpy()))\n",
    "        train_accuracy(labels, predictions)\n",
    "        return loss\n",
    "        \n",
    "    def val_step (inputs):\n",
    "        images, labels = inputs\n",
    "        predictions = model(images, training=False)\n",
    "        v_loss = loss_object(labels, predictions)\n",
    "\n",
    "        val_loss(v_loss)\n",
    "        val_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8660712838172913, Accuracy: 60.37810516357422, Test Loss: 0.9396776556968689, Test Accuracy: 67.0999984741211\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    @tf.function\n",
    "    def dist_train_step(inputs):\n",
    "        per_replica_losses = strategy.run(train_step, args=(inputs,))\n",
    "        return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis = None)\n",
    "    \n",
    "    @tf.function\n",
    "    def dist_val_step(inputs):\n",
    "        return strategy.run(val_step, args=(inputs,))\n",
    "    \n",
    "    EPOCHS = 10\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for x in train_dist_ds:\n",
    "            total_loss += dist_train_step(x)\n",
    "            num_batches += 1\n",
    "        train_loss = total_loss/num_batches\n",
    "        \n",
    "        for x in val_dist_ds:\n",
    "            dist_val_step(x)\n",
    "            \n",
    "        if epoch %2 == 0:\n",
    "            checkpoint.save(checkpoint_prefix)\n",
    "\n",
    "        template = (\"Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, \"\n",
    "                    \"Val Accuracy: {}\")\n",
    "        print(template.format(epoch+1, train_loss,\n",
    "                               train_accuracy.result()*100, val_loss.result(),\n",
    "                               val_accuracy.result()*100))\n",
    "        val_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        val_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
